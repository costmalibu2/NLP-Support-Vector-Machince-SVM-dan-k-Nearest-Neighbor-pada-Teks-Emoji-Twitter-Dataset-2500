{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Sentiment Analysis using Support Vector Machine.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ig_PIHCl5Jj"
      },
      "source": [
        "## Import Library dan Load Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBwWHF9Pl5Jm"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEQoRojPl5Jn"
      },
      "source": [
        "data_train = pd.read_excel('dataset-emosi-twitter-2500.xlsx')\n",
        "data_test = pd.read_excel('data_test.xlsx')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3eHXgA-l5Jo",
        "outputId": "806fba96-ad20-4aa9-875f-f64b2aee29e7"
      },
      "source": [
        "#untuk melihat banyak data pada data train\n",
        "\n",
        "data_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y4Zdxntl5Jp",
        "outputId": "9aa80e29-7971-4383-d98c-87a4b5a2d13a"
      },
      "source": [
        "#untuk melihat banyak data pada data test\n",
        "\n",
        "data_test.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(267, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YFlT897Ul5Jp",
        "outputId": "96aa0020-8082-4c29-b2b9-88fe64de52e0"
      },
      "source": [
        "#mengambil 5 data teratas pada data train\n",
        "\n",
        "data_train.head(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABEL</th>\n",
              "      <th>TEKS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>terkejut</td>\n",
              "      <td>@indomyfess Seokjin\\n\\nYah pas kenal Bangtan t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jijik</td>\n",
              "      <td>@JaneeeNoLimit Wkwk. Iri dengki dah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sedih</td>\n",
              "      <td>Tadi gue lewat jalan yang aga rame orang juala...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jijik</td>\n",
              "      <td>@sunrisingbok LWBSKSN yo igual muak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>terkejut</td>\n",
              "      <td>@moontygf EMG ANJRIT GUA KAGET GWS BGT NAD&lt;U+0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      LABEL                                               TEKS\n",
              "0  terkejut  @indomyfess Seokjin\\n\\nYah pas kenal Bangtan t...\n",
              "1     jijik                @JaneeeNoLimit Wkwk. Iri dengki dah\n",
              "2     sedih  Tadi gue lewat jalan yang aga rame orang juala...\n",
              "3     jijik                @sunrisingbok LWBSKSN yo igual muak\n",
              "4  terkejut  @moontygf EMG ANJRIT GUA KAGET GWS BGT NAD<U+0..."
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "L_xplQgNl5Jq",
        "outputId": "3c63772a-a2de-4287-8c6c-fa880cfcc614"
      },
      "source": [
        "#mengambi 5 data terbawah pada data train\n",
        "\n",
        "data_train.tail(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABEL</th>\n",
              "      <th>TEKS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2495</th>\n",
              "      <td>jijik</td>\n",
              "      <td>@akukeadilan_ Menyampah tengok mana yg letak s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>terkejut</td>\n",
              "      <td>main ke kampung seberang, ya Allah takjub, ini...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>terkejut</td>\n",
              "      <td>kdg takle focus tgk cerita sbb ha ramâ€™s visu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>marah</td>\n",
              "      <td>Nangroe Aceh Darussalam memang Istimewa Al Fat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>sedih</td>\n",
              "      <td>nyesek rasanya kenapa kamu setega itu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         LABEL                                               TEKS\n",
              "2495     jijik  @akukeadilan_ Menyampah tengok mana yg letak s...\n",
              "2496  terkejut  main ke kampung seberang, ya Allah takjub, ini...\n",
              "2497  terkejut  kdg takle focus tgk cerita sbb ha ramâ€™s visu...\n",
              "2498     marah  Nangroe Aceh Darussalam memang Istimewa Al Fat...\n",
              "2499     sedih              nyesek rasanya kenapa kamu setega itu"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "G81EoPEtl5Jq",
        "outputId": "f14c90fa-8c13-448f-d55b-bad4d886f092"
      },
      "source": [
        "#mengamnil 5 data secara acak pada data train\n",
        "\n",
        "data_train.sample(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABEL</th>\n",
              "      <th>TEKS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2048</th>\n",
              "      <td>marah</td>\n",
              "      <td>Positif thinking aja..susu kental manis ga ada...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>975</th>\n",
              "      <td>marah</td>\n",
              "      <td>Pencitraan terbesar kampus itu ketika mau akre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>terkejut</td>\n",
              "      <td>[Askrl] gais aku masih heran kok dokter bisa t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1777</th>\n",
              "      <td>senang</td>\n",
              "      <td>wanita yang paling malang di dunia adalah wani...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>sedih</td>\n",
              "      <td>Sayang banget ketika ada film lokal yang bagus...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         LABEL                                               TEKS\n",
              "2048     marah  Positif thinking aja..susu kental manis ga ada...\n",
              "975      marah  Pencitraan terbesar kampus itu ketika mau akre...\n",
              "119   terkejut  [Askrl] gais aku masih heran kok dokter bisa t...\n",
              "1777    senang  wanita yang paling malang di dunia adalah wani...\n",
              "757      sedih  Sayang banget ketika ada film lokal yang bagus..."
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "hKdjx7Ugl5Jr",
        "outputId": "9fba5223-b33d-4002-d769-82c799a6406a"
      },
      "source": [
        "#deskripsi data pada data train\n",
        "\n",
        "data_train.describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABEL</th>\n",
              "      <th>TEKS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2500</td>\n",
              "      <td>2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>6</td>\n",
              "      <td>2477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>terkejut</td>\n",
              "      <td>Knp sih masyarakat Indonesia itu ngeyel bgt ka...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>723</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           LABEL                                               TEKS\n",
              "count       2500                                               2500\n",
              "unique         6                                               2477\n",
              "top     terkejut  Knp sih masyarakat Indonesia itu ngeyel bgt ka...\n",
              "freq         723                                                  4"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8UPIF2Xl5Js",
        "outputId": "2dc6a07a-c229-4d20-b56d-243481d887fa"
      },
      "source": [
        "#melihat kolom pada data train\n",
        "\n",
        "data_train.columns"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['LABEL', 'TEKS'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bO4OMGQl5Js",
        "outputId": "e4da78ac-4647-40b4-9b40-2bd04517cd5c"
      },
      "source": [
        "#menghitung jumlah variabel pada kolom tweets\n",
        "data_train['TEKS'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Knp sih masyarakat Indonesia itu ngeyel bgt kalo dikasih tau. Ngerti ga sih yg namanya \"dirumah aj\" ? Anda tuh disuruh stay dirumah ama pemerintah, bukan dikasih libur/cuti. Knp harus dirumah? Knp ga boleh keluar? Karena covid-19 sedang menyerang Indonesia.    4\n",
              "Tak ada orang yang senang dengan\\nkekalahan.\\nAku merasa dongkol kalau kalah.\\nTapi, bagiku kekalahan dan luka bukanlah\\nakhir dari s ##Bot                                                                                                                          2\n",
              "paling ngeselin kalau driver udah bilang mbak yang cancel ya tapi jangan centang yang driver asked to cancel jangan ajar                                                                                                                                             2\n",
              "Serasa bangga n tepat, memilih sekolah untuk Si Kecil yg tegas memberi statement bahwa akan terus menggunakan #Kurikulum2013 SDM GKB2 Gresik                                                                                                                         2\n",
              "RT @putrakmrdn: Tolong kekalkan SOP majlis perkahwinan dengan kehadiran terhad. Sampai tahun 2050 pun tak apa. Biar makcik pakcik sedor per…                                                                                                                         2\n",
              "                                                                                                                                                                                                                                                                    ..\n",
              "@asarthurs Eh anjir kaget sumpah lu ganti ava                                                                                                                                                                                                                        1\n",
              "maaf ya mas? Maafin aku yang belum bisa kasih apa yang udah kamu kasih ke aku. Maaf aku sering buat kamu kesel ataupun sampe marah, I think I should berubah, jadi lebih nurut ke kamu, maaf kalau kata\" ini sering buat kamu muak ataupun bosen bacanya hehehe.     1\n",
              "bibi adikku si cantik suka banget liatnya kalau kamu lagi Senang enggak tau kenapa jadi ikutan Senang bi pos                                                                                                                                                         1\n",
              "bangun tidur bgt cek handphone dapet pergantian schedule klo besok harus tugas terbang ke china. langsung meleeekk, huaaa kok baru ini gue Takut mau tugas terbang                                                                                                   1\n",
              "Ya Allah, kayak tadi pagi aku lagi bantuin mama di dapur, lupa matiin WiFi di HP, jadi mungkin dia mikir ceklis 2 tapi gak di bales, terus sampe call aku, kaget bgt langsung lari ke kamar :â€™ https://t.co/om2wWPhFZj                                             1\n",
              "Name: TEKS, Length: 2477, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY02l2fkl5Js"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "fTDf9opTl5Jt",
        "outputId": "f3e8e46c-e6f0-4c06-ad96-bc3c913225aa"
      },
      "source": [
        "#melihat panjang tweet dalam data train dan data test\n",
        "\n",
        "length_train = data_train['TEKS'].str.len()\n",
        "length_test = data_test['LABEL'].str.len()\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.hist(length_train, bins=50, label=\"Train_Teks\", color = \"darkblue\")\n",
        "plt.hist(length_test, bins=50, label='Test_Teks', color = \"skyblue\")\n",
        "plt.legend()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcda0a0e450>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5OpTQYMl5Jt"
      },
      "source": [
        "### Membuat train_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EYbIE4Zl5Jt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpv4QAl_l5Ju"
      },
      "source": [
        "X=data_train.LABEL\n",
        "y=data_train.TEKS"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1O3JQ38l5Ju"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=225)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-zr4B9nl5Ju",
        "outputId": "3bf9ef13-23cb-4ee9-f79a-695dd1d4b567"
      },
      "source": [
        "#melihat pembagian data di x_train, x_test, y_train dan y_test\n",
        "\n",
        "print('Banyak data x_train :',len(x_train))\n",
        "print('Banyak data x_test  :',len(x_test))\n",
        "print('Banyak data y_train :',len(y_train))\n",
        "print('Banyak data y_test  :',len(y_test))\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Banyak data x_train : 2250\n",
            "Banyak data x_test  : 250\n",
            "Banyak data y_train : 2250\n",
            "Banyak data y_test  : 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76bGbhSNl5Ju"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4snVubFll5Jv"
      },
      "source": [
        "Pada tahap ini yang dilakukan adalah membuat data yang ada menjadi data yang lebih berkualitas atau lebih baik, dikarenakan pada data mentah masih ada yang mengandung agregat data, noisy data yang masih mengandung error dan outliers, serta ada nya data yang tidak konsisten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtS7pFH1l5Jv"
      },
      "source": [
        "import re"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbsMdw9Yl5Jv",
        "outputId": "11257b3b-3c8d-4065-e7bd-11b138d4eed6"
      },
      "source": [
        "pip install -U beautifulsoup4"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n",
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: soupsieve, beautifulsoup4\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed beautifulsoup4-4.10.0 soupsieve-2.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iVp9-0-l5Jv"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "import numpy as np"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fzoqmRgl5Jw"
      },
      "source": [
        "def proses_teks(teks):\n",
        "    soup = BeautifulSoup(teks, 'lxml')\n",
        "    souped = soup.get_text()\n",
        "    try:\n",
        "        teks = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
        "    except:\n",
        "        teks = souped\n",
        "    teks_bersih= re.sub(\"[^a-zA-Z0-9]\", \" \",(re.sub(www_pat, '', re.sub(combined_pat, '', teks)).lower()))\n",
        "    teks_bersih= ' '.join([word for word in teks_bersih.split() if word not in stopword_user])\n",
        "    return (\" \".join([x for x in tok.tokenize(teks_bersih) if len(x) > 1])).strip()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKnBmxDWl5Jw",
        "outputId": "65c328de-3fe0-446d-8ce6-ac2f31761209"
      },
      "source": [
        "merge = data_train.append(data_test, ignore_index=True, sort=False)\n",
        "merge.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2767, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuGJNnMsl5Jw"
      },
      "source": [
        "tok = WordPunctTokenizer()\n",
        "pat1 = r'@[A-Za-z0-9_]+' #menghilangkat username\n",
        "pat2 = r'https?://[^ ]+' #menghilangkan situs website\n",
        "combined_pat = r'|'.join((pat1, pat2)) #join pat1 dan pat 2\n",
        "www_pat = r'www.[^ ]+' #menghilangkan situs website"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JLguYtyl5Jw"
      },
      "source": [
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i, '', input_txt)\n",
        "    return input_txt\n",
        "\n",
        "merge['clean_teks'] = np.vectorize(remove_pattern)(merge['TEKS'], \"@[\\w]*\") #menghilangkan @user\n",
        "merge['clean_teks'] = merge['clean_teks'].str.replace(\"[^a-zA-Z#]\", \" \") #menghilangkan punctuation, angka, dan karakter\n",
        "merge['clean_teks'] = merge['clean_teks'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3])) #menghapus kata pendek"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WZmiGJ9Wl5Jw",
        "outputId": "a087993f-c465-475f-ee59-45c1b3594bbe"
      },
      "source": [
        "merge.head(5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABEL</th>\n",
              "      <th>TEKS</th>\n",
              "      <th>clean_teks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>terkejut</td>\n",
              "      <td>@indomyfess Seokjin\\n\\nYah pas kenal Bangtan t...</td>\n",
              "      <td>Seokjin kenal Bangtan tiba lihat seokjin jadi ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jijik</td>\n",
              "      <td>@JaneeeNoLimit Wkwk. Iri dengki dah</td>\n",
              "      <td>Wkwk dengki</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sedih</td>\n",
              "      <td>Tadi gue lewat jalan yang aga rame orang juala...</td>\n",
              "      <td>Tadi lewat jalan yang rame orang jualan liat d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jijik</td>\n",
              "      <td>@sunrisingbok LWBSKSN yo igual muak</td>\n",
              "      <td>LWBSKSN igual muak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>terkejut</td>\n",
              "      <td>@moontygf EMG ANJRIT GUA KAGET GWS BGT NAD&lt;U+0...</td>\n",
              "      <td>ANJRIT KAGET</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      LABEL  ...                                         clean_teks\n",
              "0  terkejut  ...  Seokjin kenal Bangtan tiba lihat seokjin jadi ...\n",
              "1     jijik  ...                                        Wkwk dengki\n",
              "2     sedih  ...  Tadi lewat jalan yang rame orang jualan liat d...\n",
              "3     jijik  ...                                 LWBSKSN igual muak\n",
              "4  terkejut  ...                                       ANJRIT KAGET\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDH027l5l5Jw"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IgwtIDpl5Jx"
      },
      "source": [
        "Tahap ini merupakan proses memecah dokumen yang terdiri dari sekumpulan kalimat menjadi bagian-bagian kata yang disebut dengan token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4njyEE0Yl5Jx",
        "outputId": "ef025d84-14dd-4303-a35c-bccc4ce40050"
      },
      "source": [
        "tokenized_tweet = merge['clean_teks'].apply(lambda x: x.split())\n",
        "tokenized_tweet.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [Seokjin, kenal, Bangtan, tiba, lihat, seokjin...\n",
              "1                                       [Wkwk, dengki]\n",
              "2    [Tadi, lewat, jalan, yang, rame, orang, jualan...\n",
              "3                               [LWBSKSN, igual, muak]\n",
              "4                                      [ANJRIT, KAGET]\n",
              "Name: clean_teks, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9UEFSI6l5Jx"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuRIs1E3l5Jx"
      },
      "source": [
        "Tahap ini merupakan mantransformasi kata menjadi kata dasar dengan menghilangkan imbuhan kata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5Z9rZyvl5Jx",
        "outputId": "2d74c9b3-e2a2-4b1b-da5f-30d47fdf5f83"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x])\n",
        "tokenized_tweet.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [seokjin, kenal, bangtan, tiba, lihat, seokjin...\n",
              "1                                       [wkwk, dengki]\n",
              "2    [tadi, lewat, jalan, yang, rame, orang, jualan...\n",
              "3                               [lwbsksn, igual, muak]\n",
              "4                                      [anjrit, kaget]\n",
              "Name: clean_teks, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkPxc-tAl5Jx"
      },
      "source": [
        "### Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nfwj8pGKl5Jx",
        "outputId": "c9522176-f987-4c06-8f16-9a42d2c4c31c"
      },
      "source": [
        "#menambahkan tweet yang sudah bersih ke dalam data frame\n",
        "\n",
        "for i in range(len(tokenized_tweet)):\n",
        "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
        "    \n",
        "merge['clean_tweet'] = tokenized_tweet\n",
        "merge.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABEL</th>\n",
              "      <th>TEKS</th>\n",
              "      <th>clean_teks</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>terkejut</td>\n",
              "      <td>@indomyfess Seokjin\\n\\nYah pas kenal Bangtan t...</td>\n",
              "      <td>Seokjin kenal Bangtan tiba lihat seokjin jadi ...</td>\n",
              "      <td>seokjin kenal bangtan tiba lihat seokjin jadi ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jijik</td>\n",
              "      <td>@JaneeeNoLimit Wkwk. Iri dengki dah</td>\n",
              "      <td>Wkwk dengki</td>\n",
              "      <td>wkwk dengki</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sedih</td>\n",
              "      <td>Tadi gue lewat jalan yang aga rame orang juala...</td>\n",
              "      <td>Tadi lewat jalan yang rame orang jualan liat d...</td>\n",
              "      <td>tadi lewat jalan yang rame orang jualan liat d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jijik</td>\n",
              "      <td>@sunrisingbok LWBSKSN yo igual muak</td>\n",
              "      <td>LWBSKSN igual muak</td>\n",
              "      <td>lwbsksn igual muak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>terkejut</td>\n",
              "      <td>@moontygf EMG ANJRIT GUA KAGET GWS BGT NAD&lt;U+0...</td>\n",
              "      <td>ANJRIT KAGET</td>\n",
              "      <td>anjrit kaget</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      LABEL  ...                                        clean_tweet\n",
              "0  terkejut  ...  seokjin kenal bangtan tiba lihat seokjin jadi ...\n",
              "1     jijik  ...                                        wkwk dengki\n",
              "2     sedih  ...  tadi lewat jalan yang rame orang jualan liat d...\n",
              "3     jijik  ...                                 lwbsksn igual muak\n",
              "4  terkejut  ...                                       anjrit kaget\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K377mSY-l5Jy"
      },
      "source": [
        "### Visualiasasi dengan data yang sudah bersih, dengan menggunakan Word Cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGrsdMCEl5Jy"
      },
      "source": [
        "#untuk melihat sentimen yang ada pada seluruh data train. Dapat dilihat dengan memahami kata yang umum dengan plot word cloud\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "def plot_wordCloud(words):\n",
        "    wordCloud = WordCloud(width=800, height=500, background_color='white', random_state=21, max_font_size=120).generate(words)\n",
        "    \n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.imshow(wordCloud, interpolation='bilinear')\n",
        "    plt.axis('off')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KinR4d1pl5Jz"
      },
      "source": [
        "## Extracting Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw3c_cVwl5Jz"
      },
      "source": [
        "### Bag-of-words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSziNPmml5Jz"
      },
      "source": [
        "Bag of word merupakan representasi penyederhanaan yang digunakan dalam NLP. Dalam model ini, direpresentasi sebagai bag (multiset) kata-katanya, mengabaikan tata bahasa dan urutan kata tetapi tetap berkembang"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-Y8Fqdwl5Jz"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
        "bow = bow_vectorizer.fit_transform(merge['clean_teks'])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2C_ebZgl5Jz"
      },
      "source": [
        "### TF_IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuBv8bBrl5Jz"
      },
      "source": [
        "TF-IDF atau Term Frequency-Inverse Document Frequency, merupakan proses pemberian bobot term pada dokumen. Pembobotan ini dogunakan untuk melakukan klasifikasi data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6-5YQezl5Jz"
      },
      "source": [
        "tfidf_vectorizer = CountVectorizer(max_df=0.90, max_features=1000, stop_words='english')\n",
        "tfidf = bow_vectorizer.fit_transform(merge['clean_teks'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvQg2mKLl5Jz"
      },
      "source": [
        "### Word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCUvJLLfl5J0"
      },
      "source": [
        "Word2vec adalah metode embedding word yang berguna untuk mempresentasikan kata menjadi sebuah vektor dengan panjang N. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G0iHFtHl5J0",
        "outputId": "a82a280a-92d5-4a90-f7c3-3380088e3dc0"
      },
      "source": [
        "tokenized_tweet = merge['clean_teks'].apply(lambda x: x.split()) #tokenize\n",
        "\n",
        "import gensim\n",
        "model_w2v = gensim.models.Word2Vec(\n",
        "            tokenized_tweet,\n",
        "            size=200,\n",
        "            window = 5, #ukuran jendela\n",
        "            min_count =2,\n",
        "            sg = 1, #skip gram model\n",
        "            hs = 0,\n",
        "            negative = 10, #jumlah contoh kata negatif\n",
        "            workers = 2,\n",
        "            seed = 34)\n",
        "\n",
        "model_w2v.train(tokenized_tweet, total_examples= len(merge['clean_teks']), epochs=20)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(611576, 807100)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFTIcUlgl5J0"
      },
      "source": [
        "def word_vector(tokens, size):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0.\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += model_w2v[word].reshape((1, size))\n",
        "            count += 1.\n",
        "        except KeyError: # apabila ada kasus dimana token tidak ada dalam kosa kata\n",
        "                         \n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xYxNPx2l5J0",
        "outputId": "ad8f8dc6-6a77-4199-dab7-902159dc0540"
      },
      "source": [
        "wordvec_arrays = np.zeros((len(tokenized_tweet), 200))\n",
        "\n",
        "for i in range(len(tokenized_tweet)):\n",
        "    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 200)\n",
        "    \n",
        "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
        "wordvec_df.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2767, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfR07ucSl5J0"
      },
      "source": [
        "## Classification SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENxJbttSl5J0"
      },
      "source": [
        "#### Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSpaCfdev14l"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNQQXk5ql5J1"
      },
      "source": [
        "SVM merupakan salah satu metode klasifikasi dengan menemukan hyperplance yang membedakan dua kelas dengan baik. Teknik ini digunakan untuk mentranformasikan data dan kemudian menemukan batas optimal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsQJci6pl5J1"
      },
      "source": [
        "Bag-of-words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_yjg_egl5J1"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import accuracy_score, make_scorer\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,KFold\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error, make_scorer,classification_report,confusion_matrix,accuracy_score,roc_auc_score,roc_curve"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "-LPzpZDRl5J1",
        "outputId": "e72ae924-a885-44e7-9bc4-6b9cd879ae90"
      },
      "source": [
        "train_bow = bow[:319620,:]\n",
        "test_bow = bow[319620:,:]\n",
        "\n",
        "#ganti data ke training dan validasi set\n",
        "xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train_bow, data_train['LABEL'], random_state=42, test_size=0.4)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-ae2738c46518>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#ganti data ke training dan validasi set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mxtrain_bow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mxvalid_bow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xtrain_bow' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vTlSpA5l5J1"
      },
      "source": [
        "svc = svm.SVC(kernel='linear', C=1, probability=True).fit(xtrain_bow, ytrain)\n",
        "\n",
        "prediction = svc.predict_proba(xvalid_bow)\n",
        "prediction_int = prediction[:,1] >= 0.3\n",
        "prediction_int = prediction_int.astype(np.int)\n",
        "F1_Score = f1_score(yvalid, prediction_int) #menghitung f1-score\n",
        "print('Precision score: ', precision_score(yvalid, prediction_int, average=None)) #menghitung precision score\n",
        "print('Accuracy Score: ', accuracy_score(yvalid, prediction_int)) #menghitung accuracy score\n",
        "print(f'F1_Score: {F1_Score}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9nAQYfkl5J1"
      },
      "source": [
        "TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmeIWkjel5J1"
      },
      "source": [
        "train_tfidf = bow[:31962,:]\n",
        "test_tfidf = bow[31962:,:]\n",
        "\n",
        "#ganti data ke training dan validasi set\n",
        "xtrain_tfidf, xvalid_tfidf, ytrain, yvalid = train_test_split(train_tfidf, data_train['label'], random_state=42, test_size=0.5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt3z_4Lul5J1"
      },
      "source": [
        "svc = svm.SVC(kernel='linear', C=1, probability=True).fit(xtrain_tfidf, ytrain)\n",
        "\n",
        "prediction = svc.predict_proba(xvalid_tfidf)\n",
        "prediction_int = prediction[:,1] >= 0.3\n",
        "prediction_int = prediction_int.astype(np.int)\n",
        "F1_Score = f1_score(yvalid, prediction_int) #menghitung f1-score\n",
        "print('Precision score: ', precision_score(yvalid, prediction_int, average=None)) #menghitung precision_score\n",
        "print('Accuracy Score: ', accuracy_score(yvalid, prediction_int)) #menghitung accuracy score\n",
        "print(f'F1_Score: {F1_Score}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKu_KHCRl5J2"
      },
      "source": [
        "Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLkeq3Prl5J2"
      },
      "source": [
        "train_w2v = wordvec_df.iloc[:31962,:]\n",
        "test_w2v = wordvec_df.iloc[31962:,:]\n",
        "\n",
        "xtrain_w2v = train_w2v.iloc[ytrain.index,:]\n",
        "xvalid_w2v = train_w2v.iloc[yvalid.index,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3k9qe71l5J2"
      },
      "source": [
        "svc = svm.SVC(kernel='linear', C=1, probability=True).fit(xtrain_w2v, ytrain)\n",
        "\n",
        "prediction = svc.predict_proba(xvalid_w2v)\n",
        "prediction_int = prediction[:,1] >= 0.3\n",
        "prediction_int = prediction_int.astype(np.int)\n",
        "F1_Score = f1_score(yvalid, prediction_int) # menghitung f1 score\n",
        "print('Precision score: ', precision_score(yvalid, prediction_int, average=None)) #menghitung precision score\n",
        "print('Accuracy Score: ', accuracy_score(yvalid, prediction_int)) #menghitung accuracy score\n",
        "print(f'F1_Score: {F1_Score}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaKhTT3Ul5J2"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdNiEVrel5J2"
      },
      "source": [
        "MODEL_ID = []\n",
        "Accuracy = []\n",
        "LOG_CV_ERR = []\n",
        "F1Score = []\n",
        "def calculate_log_cv_error(logmodel,X_train,y_train):\n",
        "    ms_errors= cross_val_score(logmodel, X_train, y_train, cv=5, scoring = make_scorer(mean_squared_error))\n",
        "    rms_errors = np.sqrt(ms_errors)\n",
        "    mean_rms_error = rms_errors.mean()\n",
        "    return mean_rms_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_7luJ1ll5J2"
      },
      "source": [
        "def evaluate_model(logmodel,X_train,X_test,y_train,y_test,predictions):\n",
        "    log_cv_error = calculate_log_cv_error(logmodel,X_train,y_train)\n",
        "    print(f'\\nClassification Report:\\n{classification_report(y_test,predictions)}')\n",
        "    print('')\n",
        "    print(f'\\nConfusion Matrix:\\n{confusion_matrix(y_test,predictions)}')\n",
        "    print('')\n",
        "    print (f'\\nAccuracy Score:  {accuracy_score(y_test,predictions)}')\n",
        "    print(\"Cross Validation Error: \",log_cv_error)\n",
        "    logit_roc_auc = roc_auc_score(y_test, logmodel.predict(X_test))\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, logmodel.predict_proba(X_test)[:,1])\n",
        "    LOG_CV_ERR.append(log_cv_error)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCVwPqr9l5J2"
      },
      "source": [
        "evaluate_model(svc,xtrain_w2v,xvalid_w2v,ytrain,yvalid,prediction_int)\n",
        "MODEL_ID.append('Support Vector Classifier')\n",
        "Accuracy.append(accuracy_score(yvalid, prediction_int))\n",
        "F1Score.append(f1_score(yvalid, prediction_int))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9TUQNmSl5J3"
      },
      "source": [
        "SVM bekerja sangat baik dengan batas pemisah yang jelas pada dua karakteristik dan ruang berdimensi yang tinggi."
      ]
    }
  ]
}